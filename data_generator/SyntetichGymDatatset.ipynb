{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hialznDbFCjt"
      },
      "source": [
        "# **Synthetic Gym Dataset Generator (Set-Level)**\n",
        "\n",
        "**Generatore di dataset sintetico realistico per allenamento in palestra**\n",
        "\n",
        "---\n",
        "\n",
        "## **Overview**\n",
        "\n",
        "Dataset con simulazione dinamica:\n",
        "- **Finestra temporale variabile** per utente (2 settimane → 2 anni)\n",
        "- **Simulazione a stati** (fitness, fatigue, skill, resilience)\n",
        "- **Eventi realistici** (skip, injury)\n",
        "- **Progressive overload** con transfer tra esercizi\n",
        "- **Modello Banister** per fitness/fatigue\n",
        "\n",
        "### **File Output**\n",
        "- `workout_sets.csv` — Set-level (principale)\n",
        "- `workout_logs.csv` — Exercise-level\n",
        "- `sessions.csv` — Session-level\n",
        "- `banister_daily.csv` — Serie F/D/P\n",
        "- `users.csv`, `workouts.csv`, `workout_plan.csv`\n",
        "\n",
        "### **Parametri Chiave**\n",
        "- `n_users`: 300 (modificabile)\n",
        "- `seed`: 27 (riproducibilità)\n",
        "- `overload_base_rate`: Beginner 5%, Intermediate 0.5%, Advanced 0.4%\n",
        "\n",
        " **Tempo esecuzione**: ~5-8 minuti per 300 utenti\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCiAXsOeFCju"
      },
      "source": [
        "---\n",
        "# 1. **Setup & Imports**\n",
        "\n",
        "Installazione librerie e import moduli.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-sMjqHZhl_G"
      },
      "source": [
        "# Synthetic Gym Logs Generator (Set-level)\n",
        "Generatore di dataset sintetico per log di allenamento **per serie** (set-level) con:\n",
        "- finestra temporale per utente variabile (end_date tra oggi e +2 anni, durata 2 settimane → 2 anni)\n",
        "- simulazione a stati (fitness/fatigue/skill/resilience)\n",
        "- eventi (skip, injury)\n",
        "- output canonico: `workout_sets.csv`\n",
        "- output derivati: `workoutlogs.csv` (per esercizio), `sessions.csv` (per sessione), `banisterdaily.csv`\n",
        "\n",
        "Obiettivo: produrre dati realistici e poi derivare viste aggregate per i moduli ML.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wxo0kBLhsAZ"
      },
      "source": [
        "**CELL 1 — (Python) Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SovnHCMDhz0y"
      },
      "outputs": [],
      "source": [
        "!pip -q install pandas numpy\n",
        "\n",
        "import os, json, math\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from datetime import date, timedelta, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btynhxwMFCjv"
      },
      "source": [
        "---\n",
        "#2. **Configurazione**\n",
        "\n",
        "Definizione parametri globali:\n",
        "\n",
        "### **User Generation**\n",
        "- `n_users`: numero utenti\n",
        "- `seed`: random seed\n",
        "\n",
        "### **Date Ranges**\n",
        "- `today`: data riferimento\n",
        "- `end_date_max_days_ahead`: max giorni futuro\n",
        "- `min/max_duration_days`: range durata finestra\n",
        "\n",
        "### **Training Schedule**\n",
        "- `weekly_freq_mu/sd`: frequenza settimanale\n",
        "- `weekday_jitter_probs`: jitter giorni\n",
        "\n",
        "### **Progressive Overload**\n",
        "- `overload_base_rate`: tasso crescita per livello\n",
        "- `transfer_same_muscle`: 35% (stesso gruppo muscolare)\n",
        "- `transfer_same_split`: 12% (stesso split)\n",
        "\n",
        "### **Skip & Injury**\n",
        "- `skip_p0_by_level`: probabilità baseline skip\n",
        "- `skip_fatigue_weight`: modulazione fatica\n",
        "- `injury_lambda`: scala probabilità infortunio\n",
        "\n",
        "### **Banister**\n",
        "- `tauF`: ~45 giorni (fitness decay)\n",
        "- `tauD`: ~7 giorni (fatigue decay)\n",
        "- `betaF/betaD`: coefficienti\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbnjzVEqh2RC"
      },
      "source": [
        "**CELL 2 — (Python) Config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojCQRcDBh4al",
        "outputId": "45b5988c-a822-432c-f7d9-a69bfbf51fe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.date(2026, 2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "@dataclass\n",
        "class CFG:\n",
        "    seed: int = 27\n",
        "    outdir: str = \"data_synth_setlevel\"\n",
        "\n",
        "    n_users: int = 1000\n",
        "\n",
        "    # Per-user date ranges\n",
        "    today: date = date.today()\n",
        "    end_date_max_days_ahead: int = 730     # oggi -> +2 anni\n",
        "    min_duration_days: int = 14           # 2 settimane\n",
        "    max_duration_days: int = 730          # 2 anni\n",
        "\n",
        "    # Training schedule\n",
        "    weekly_freq_mu: float = 3.5\n",
        "    weekly_freq_sd: float = 1.0\n",
        "    weekly_freq_min: int = 1\n",
        "    weekly_freq_max: int = 6\n",
        "    weekday_jitter_probs = (0.15, 0.70, 0.15)  # -1,0,+1\n",
        "\n",
        "    # Quantization / realism\n",
        "    load_step: float = 0.25\n",
        "    rpe_step: float = 0.5\n",
        "\n",
        "    # Skip model (baseline per livello)\n",
        "    skip_p0_by_level: dict = None  # lo definiamo sotto\n",
        "    # quanto la fatica aumenta lo skip (modulatore leggero)\n",
        "    skip_fatigue_weight: float = 0.25\n",
        "    skip_fatigue_cap: float = 1.2\n",
        "    skip_noise_sd: float = 0.10\n",
        "\n",
        "    # cap e rumore (tengono stabile il sistema)\n",
        "    skip_fatigue_cap = 1.2\n",
        "    skip_noise_sd = 0.10\n",
        "\n",
        "    skip_exp_fatigue_scale = 0.85   # quanto l’esperienza \"spegne\" l’effetto fatica (0.0=nessun effetto)\n",
        "\n",
        "    skip_exp_weight: float = 1.2\n",
        "\n",
        "    injury_lambda: float = 0.002   # scala probabilità injury\n",
        "    injury_days_min: int = 7\n",
        "    injury_days_max: int = 28\n",
        "\n",
        "    # Missingness (solo su osservazioni)\n",
        "    p_missing_rpe: float = 0.02\n",
        "    p_missing_load: float = 0.01\n",
        "    p_missing_feedback: float = 0.02\n",
        "\n",
        "    # Banister-like params\n",
        "    tauF_mean: float = 45.0\n",
        "    tauF_sd: float = 8.0\n",
        "    tauD_mean: float = 7.0\n",
        "    tauD_sd: float = 2.0\n",
        "    betaF: float = 0.010\n",
        "    betaD: float = 0.015\n",
        "\n",
        "    # === PROGRESSIVE OVERLOAD (dose-driven) ===\n",
        "    overload_base_rate: dict = None      # tasso crescita per livello\n",
        "    overload_I0: float = 1800.0          # impulse normalizzazione (mediana attesa)\n",
        "    overload_quality_fatigue: float = 0.6  # quanto la fatica riduce quality\n",
        "    # Transfer weights\n",
        "    transfer_same_muscle: float = 0.35   # stesso targetmusclegroup\n",
        "    transfer_same_split: float = 0.12    # stesso splitcat\n",
        "\n",
        "\n",
        "# Default per skip_p0_by_level\n",
        "if not hasattr(CFG, '__dataclass_fields__') or 'skip_p0_by_level' not in CFG.__dataclass_fields__:\n",
        "    CFG.skip_p0_by_level = {\n",
        "      \"Beginner\": 0.10,      # era 0.13 → abbassato per target ~12-13%\n",
        "      \"Intermediate\": 0.065,  # era 0.08 → abbassato per target ~8%\n",
        "      \"Advanced\": 0.05,       # già perfetto, lasciato invariato\n",
        "}\n",
        "\n",
        "cfg = CFG()\n",
        "\n",
        "cfg.skip_p0_by_level = {\n",
        "    \"Beginner\": 0.10,\n",
        "    \"Intermediate\": 0.065,\n",
        "    \"Advanced\": 0.05,\n",
        "}\n",
        "\n",
        "cfg.overload_base_rate = {\n",
        "    \"Beginner\": 0.0500,      # ← DA 0.0180 A 0.0300 (x2.7)\n",
        "    \"Intermediate\": 0.0050,  # OK\n",
        "    \"Advanced\": 0.0040,      # OK\n",
        "}\n",
        "\n",
        "rng = np.random.default_rng(cfg.seed)\n",
        "\n",
        "OUTDIR = Path(cfg.outdir)\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cfg.today\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie8oCXjhFCjv"
      },
      "source": [
        "---\n",
        "#3. **Utility Functions**\n",
        "\n",
        "Funzioni helper:\n",
        "- `sigmoid(z)` — Sigmoide per probabilità\n",
        "- `logit(p)` — Inverse sigmoid\n",
        "- `qload(x, step)` — Quantizzazione carico (0.25 kg)\n",
        "- `qrpe(x, step)` — Quantizzazione RPE (0.5)\n",
        "- `clamp_int()` — Clamp + cast\n",
        "- `sample_split()` — PPL 70% / FullBody 30%\n",
        "- `exp_weights()` — Pesi esponenziali Banister\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46HTer4uh6fO"
      },
      "source": [
        "**CELL 3 — (Python) Utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMlUVblQh_ed"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z: float) -> float:\n",
        "    return 1.0 / (1.0 + math.exp(-z))\n",
        "\n",
        "def qload(x: float, step: float) -> float:\n",
        "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
        "        return np.nan\n",
        "    return float(np.round(x / step) * step)\n",
        "\n",
        "def qrpe(x: float, step: float) -> float:\n",
        "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
        "        return np.nan\n",
        "    x = float(np.clip(x, 1.0, 10.0))\n",
        "    return float(np.round(x / step) * step)\n",
        "\n",
        "def clamp_int(x, lo, hi):\n",
        "    return int(np.clip(int(round(x)), lo, hi))\n",
        "\n",
        "def sample_split(rng):\n",
        "    return str(rng.choice([\"PPL\", \"FullBody\"], p=[0.7, 0.3]))\n",
        "\n",
        "def exp_weights(L: int, tau: float) -> np.ndarray:\n",
        "    idx = np.arange(L, dtype=float)\n",
        "    return np.exp(-idx / float(tau))\n",
        "\n",
        "def logit(p: float) -> float:\n",
        "    \"\"\"Inverse sigmoid: logit(p) = ln(p/(1-p))\"\"\"\n",
        "    return math.log(p/(1-p))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRNTS2hwFCjv"
      },
      "source": [
        "### **Verifica Configurazione Skip Model**\n",
        "\n",
        "Test che parametri skip siano caricati e `logit()` sia definita.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oELCe8vWs3yX",
        "outputId": "1a24aa27-caa9-4e23-eb32-a74326aae5d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Controllo configurazione skip:\n",
            "  cfg.skip_p0_by_level = {'Beginner': 0.1, 'Intermediate': 0.065, 'Advanced': 0.05}\n",
            "  cfg.skip_fatigue_weight = 0.25\n",
            "logit(0.10) = -2.197\n"
          ]
        }
      ],
      "source": [
        "# === VERIFICA CONFIG ===\n",
        "print(\"Controllo configurazione skip:\")\n",
        "print(f\"  cfg.skip_p0_by_level = {cfg.skip_p0_by_level}\")\n",
        "print(f\"  cfg.skip_fatigue_weight = {cfg.skip_fatigue_weight}\")\n",
        "\n",
        "try:\n",
        "    test_val = logit(0.10)\n",
        "    print(f\"logit(0.10) = {test_val:.3f}\")\n",
        "except NameError:\n",
        "    print(\"ERRORE: logit() non è definita!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSsw3tP1FCjv"
      },
      "source": [
        "---\n",
        "#4. **Exercise Catalog**\n",
        "\n",
        "Caricamento catalogo esercizi con fallback.\n",
        "\n",
        "### **Funzionamento**\n",
        "1. Tenta caricamento `esercizi_catalogo.csv`\n",
        "2. Se non trovato: fallback a 12 esercizi base\n",
        "3. Normalizzazione colonne (italiano → inglese)\n",
        "\n",
        "### **Schema**\n",
        "- `exerciseid`, `name`, `targetmusclegroup`\n",
        "- `mechanics` (Compound/Isolation)\n",
        "- `difficultylevel` (Beginner/Intermediate/Advanced)\n",
        "- `equipment`, `bodyregion`, `splitcat` (push/pull/legs/core/other)\n",
        "\n",
        "**NOTA Con fallback**: solo 12 esercizi ma funzionale.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWu5yD2HiBVi"
      },
      "source": [
        "**CELL 4 — (Python) Load exercise catalog (fallback incluso)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2rmaWBQHiIfS",
        "outputId": "e6179ccc-6a9d-4072-a824-cfa64e71e21b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   exerciseid          name targetmusclegroup  mechanics difficultylevel  \\\n",
              "0           1   Bench Press             Chest   Compound    Intermediate   \n",
              "1           2   Barbell Row              Back   Compound    Intermediate   \n",
              "2           3         Squat        Quadriceps   Compound        Advanced   \n",
              "3           4     Cable Fly             Chest  Isolation        Beginner   \n",
              "4           5  Lat Pulldown              Back   Compound        Beginner   \n",
              "\n",
              "  equipment  bodyregion splitcat  \n",
              "0   Barbell  Upper Body     push  \n",
              "1   Barbell  Upper Body     pull  \n",
              "2   Barbell  Lower Body     legs  \n",
              "3     Cable  Upper Body     push  \n",
              "4   Machine  Upper Body     pull  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7822dc34-4457-4ec1-8b35-f64742d9c0bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exerciseid</th>\n",
              "      <th>name</th>\n",
              "      <th>targetmusclegroup</th>\n",
              "      <th>mechanics</th>\n",
              "      <th>difficultylevel</th>\n",
              "      <th>equipment</th>\n",
              "      <th>bodyregion</th>\n",
              "      <th>splitcat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Bench Press</td>\n",
              "      <td>Chest</td>\n",
              "      <td>Compound</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>Barbell</td>\n",
              "      <td>Upper Body</td>\n",
              "      <td>push</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Barbell Row</td>\n",
              "      <td>Back</td>\n",
              "      <td>Compound</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>Barbell</td>\n",
              "      <td>Upper Body</td>\n",
              "      <td>pull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Squat</td>\n",
              "      <td>Quadriceps</td>\n",
              "      <td>Compound</td>\n",
              "      <td>Advanced</td>\n",
              "      <td>Barbell</td>\n",
              "      <td>Lower Body</td>\n",
              "      <td>legs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Cable Fly</td>\n",
              "      <td>Chest</td>\n",
              "      <td>Isolation</td>\n",
              "      <td>Beginner</td>\n",
              "      <td>Cable</td>\n",
              "      <td>Upper Body</td>\n",
              "      <td>push</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Lat Pulldown</td>\n",
              "      <td>Back</td>\n",
              "      <td>Compound</td>\n",
              "      <td>Beginner</td>\n",
              "      <td>Machine</td>\n",
              "      <td>Upper Body</td>\n",
              "      <td>pull</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7822dc34-4457-4ec1-8b35-f64742d9c0bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7822dc34-4457-4ec1-8b35-f64742d9c0bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7822dc34-4457-4ec1-8b35-f64742d9c0bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_ex",
              "summary": "{\n  \"name\": \"df_ex\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"exerciseid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"Seated Cable Row\",\n          \"Incline DB Press\",\n          \"Bench Press\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"targetmusclegroup\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Chest\",\n          \"Back\",\n          \"Hamstrings\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mechanics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Isolation\",\n          \"Compound\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"difficultylevel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Intermediate\",\n          \"Advanced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"equipment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Cable\",\n          \"Dumbbell\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bodyregion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Upper Body\",\n          \"Lower Body\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"splitcat\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pull\",\n          \"core\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def load_exercises_catalog(path: str = \"esercizi_catalogo.csv\") -> pd.DataFrame:\n",
        "    p = Path(path)\n",
        "    if p.exists():\n",
        "        df = pd.read_csv(p)\n",
        "\n",
        "        rename_map = {\n",
        "            \"idEsercizio\": \"exerciseid\",\n",
        "            \"nome\": \"name\",\n",
        "            \"gruppoMuscolare\": \"targetmusclegroup\",\n",
        "            \"livelloEsercizio\": \"difficultylevel\",\n",
        "            \"Mechanics\": \"mechanics\"\n",
        "        }\n",
        "        for k, v in rename_map.items():\n",
        "            if k in df.columns and v not in df.columns:\n",
        "                df = df.rename(columns={k: v})\n",
        "        if \"splitcat\" not in df.columns:\n",
        "            df[\"splitcat\"] = \"other\"\n",
        "        keep = [\"exerciseid\",\"name\",\"targetmusclegroup\",\"mechanics\",\"difficultylevel\",\n",
        "                \"equipment\",\"bodyregion\",\"splitcat\"]\n",
        "        for c in keep:\n",
        "            if c not in df.columns:\n",
        "                df[c] = None\n",
        "        df = df[keep].copy()\n",
        "        df[\"exerciseid\"] = df[\"exerciseid\"].astype(int)\n",
        "        df[\"splitcat\"] = df[\"splitcat\"].astype(str).str.lower()\n",
        "        return df.sort_values(\"exerciseid\").reset_index(drop=True)\n",
        "\n",
        "    # Fallback minimale (estendibile)\n",
        "    rows = [\n",
        "        (1,\"Bench Press\",\"Chest\",\"Compound\",\"Intermediate\",\"Barbell\",\"Upper Body\",\"push\"),\n",
        "        (2,\"Barbell Row\",\"Back\",\"Compound\",\"Intermediate\",\"Barbell\",\"Upper Body\",\"pull\"),\n",
        "        (3,\"Squat\",\"Quadriceps\",\"Compound\",\"Advanced\",\"Barbell\",\"Lower Body\",\"legs\"),\n",
        "        (4,\"Cable Fly\",\"Chest\",\"Isolation\",\"Beginner\",\"Cable\",\"Upper Body\",\"push\"),\n",
        "        (5,\"Lat Pulldown\",\"Back\",\"Compound\",\"Beginner\",\"Machine\",\"Upper Body\",\"pull\"),\n",
        "        (6,\"Leg Press\",\"Quadriceps\",\"Compound\",\"Intermediate\",\"Machine\",\"Lower Body\",\"legs\"),\n",
        "        (7,\"Plank\",\"Abdominals\",\"Compound\",\"Beginner\",\"Bodyweight\",\"Core\",\"core\"),\n",
        "        (8,\"Lateral Raise\",\"Shoulders\",\"Isolation\",\"Beginner\",\"Dumbbell\",\"Upper Body\",\"push\"),\n",
        "        (9,\"Romanian Deadlift\",\"Hamstrings\",\"Compound\",\"Advanced\",\"Barbell\",\"Lower Body\",\"legs\"),\n",
        "        (10,\"Incline DB Press\",\"Chest\",\"Compound\",\"Intermediate\",\"Dumbbell\",\"Upper Body\",\"push\"),\n",
        "        (11,\"Seated Cable Row\",\"Back\",\"Compound\",\"Beginner\",\"Cable\",\"Upper Body\",\"pull\"),\n",
        "        (12,\"Leg Curl\",\"Hamstrings\",\"Isolation\",\"Beginner\",\"Machine\",\"Lower Body\",\"legs\"),\n",
        "    ]\n",
        "    return pd.DataFrame(rows, columns=[\n",
        "        \"exerciseid\",\"name\",\"targetmusclegroup\",\"mechanics\",\"difficultylevel\",\n",
        "        \"equipment\",\"bodyregion\",\"splitcat\"\n",
        "    ])\n",
        "\n",
        "df_ex = load_exercises_catalog()\n",
        "df_ex.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m6AK_wbFCjw"
      },
      "source": [
        "---\n",
        "#5. **User Generation**\n",
        "\n",
        "Generazione utenti con **latenti** e finestre temporali individuali.\n",
        "\n",
        "## **User Latents (Variabili Nascoste)**\n",
        "\n",
        "### **Experience Latent**\n",
        "- Continuo ∈ [0, 1] → Discretizzato:\n",
        "  - **Beginner** (< 0.40)\n",
        "  - **Intermediate** (0.40-0.80)\n",
        "  - **Advanced** (> 0.80)\n",
        "\n",
        "### **Adaptation Parameters**\n",
        "- `alpha_adapt`: tasso adattamento (↑ per beginner)\n",
        "- `k_detraining`: tasso detraining (↑ per beginner)\n",
        "- `obs_noise`: rumore osservazioni (↑ per beginner)\n",
        "\n",
        "### **Individual Differences**\n",
        "- `resilience`: resistenza infortuni (↑ per advanced)\n",
        "- `fatigue_sens`: sensibilità fatica\n",
        "- `rpe_report_bias`: bias soggettivo RPE\n",
        "\n",
        "## **Date Window**\n",
        "Ogni utente ha `start_date` e `end_date` individuali → simula dataset \"real-world\".\n",
        "\n",
        "## **Output**\n",
        "`df_users`: anagrafica + date window + label target + latenti\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lDBDsfUiKhH"
      },
      "source": [
        "**CELL 5 — (Python) Sample user latents + per-user date windows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "ILGOMkqLiOB2",
        "outputId": "523fe2e3-d1a4-463b-aab2-0a12ee56aaf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userid  weeklyfreqdeclared splittype  start_date    end_date  \\\n",
              "0       1                   4       PPL  2024-09-06  2026-02-02   \n",
              "1       2                   4       PPL  2024-04-13  2026-02-06   \n",
              "2       3                   4  FullBody  2026-02-26  2026-05-30   \n",
              "3       4                   3  FullBody  2025-01-21  2026-03-12   \n",
              "4       5                   4       PPL  2025-02-12  2026-06-04   \n",
              "\n",
              "  experience_label  experience_latent  alpha_adapt  k_detraining  obs_noise  \\\n",
              "0         Beginner             0.2995      0.05222       0.01466     0.1321   \n",
              "1     Intermediate             0.4700      0.03279       0.01361     0.1870   \n",
              "2         Beginner             0.2713      0.04981       0.01256     0.2242   \n",
              "3     Intermediate             0.4448      0.05200       0.01132     0.2132   \n",
              "4         Beginner             0.2797      0.03763       0.02190     0.2159   \n",
              "\n",
              "   resilience  fatigue_sens  rpe_report_bias  \n",
              "0      1.0623        0.5385          -0.6439  \n",
              "1      0.9602        0.9363           0.3472  \n",
              "2      1.5184        0.6392           0.2331  \n",
              "3      1.4421        0.8406           0.2141  \n",
              "4      1.0132        0.6727           0.4974  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f049b9cc-ecb6-4944-8a51-8e1726b77baf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>weeklyfreqdeclared</th>\n",
              "      <th>splittype</th>\n",
              "      <th>start_date</th>\n",
              "      <th>end_date</th>\n",
              "      <th>experience_label</th>\n",
              "      <th>experience_latent</th>\n",
              "      <th>alpha_adapt</th>\n",
              "      <th>k_detraining</th>\n",
              "      <th>obs_noise</th>\n",
              "      <th>resilience</th>\n",
              "      <th>fatigue_sens</th>\n",
              "      <th>rpe_report_bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>PPL</td>\n",
              "      <td>2024-09-06</td>\n",
              "      <td>2026-02-02</td>\n",
              "      <td>Beginner</td>\n",
              "      <td>0.2995</td>\n",
              "      <td>0.05222</td>\n",
              "      <td>0.01466</td>\n",
              "      <td>0.1321</td>\n",
              "      <td>1.0623</td>\n",
              "      <td>0.5385</td>\n",
              "      <td>-0.6439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>PPL</td>\n",
              "      <td>2024-04-13</td>\n",
              "      <td>2026-02-06</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>0.4700</td>\n",
              "      <td>0.03279</td>\n",
              "      <td>0.01361</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>0.9602</td>\n",
              "      <td>0.9363</td>\n",
              "      <td>0.3472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>FullBody</td>\n",
              "      <td>2026-02-26</td>\n",
              "      <td>2026-05-30</td>\n",
              "      <td>Beginner</td>\n",
              "      <td>0.2713</td>\n",
              "      <td>0.04981</td>\n",
              "      <td>0.01256</td>\n",
              "      <td>0.2242</td>\n",
              "      <td>1.5184</td>\n",
              "      <td>0.6392</td>\n",
              "      <td>0.2331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>FullBody</td>\n",
              "      <td>2025-01-21</td>\n",
              "      <td>2026-03-12</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>0.4448</td>\n",
              "      <td>0.05200</td>\n",
              "      <td>0.01132</td>\n",
              "      <td>0.2132</td>\n",
              "      <td>1.4421</td>\n",
              "      <td>0.8406</td>\n",
              "      <td>0.2141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>PPL</td>\n",
              "      <td>2025-02-12</td>\n",
              "      <td>2026-06-04</td>\n",
              "      <td>Beginner</td>\n",
              "      <td>0.2797</td>\n",
              "      <td>0.03763</td>\n",
              "      <td>0.02190</td>\n",
              "      <td>0.2159</td>\n",
              "      <td>1.0132</td>\n",
              "      <td>0.6727</td>\n",
              "      <td>0.4974</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f049b9cc-ecb6-4944-8a51-8e1726b77baf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f049b9cc-ecb6-4944-8a51-8e1726b77baf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f049b9cc-ecb6-4944-8a51-8e1726b77baf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_users",
              "summary": "{\n  \"name\": \"df_users\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"userid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          522,\n          738,\n          741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weeklyfreqdeclared\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"splittype\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"FullBody\",\n          \"PPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 662,\n        \"samples\": [\n          \"2025-06-15\",\n          \"2026-06-01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 535,\n        \"samples\": [\n          \"2026-12-28\",\n          \"2027-08-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Beginner\",\n          \"Intermediate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience_latent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22133380643856138,\n        \"min\": 0.0147,\n        \"max\": 0.9906,\n        \"num_unique_values\": 931,\n        \"samples\": [\n          0.6037,\n          0.5651\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha_adapt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012144257492561887,\n        \"min\": 0.005,\n        \"max\": 0.07697,\n        \"num_unique_values\": 904,\n        \"samples\": [\n          0.01811,\n          0.04259\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k_detraining\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004679338159260206,\n        \"min\": 0.002,\n        \"max\": 0.02744,\n        \"num_unique_values\": 732,\n        \"samples\": [\n          0.01282,\n          0.01481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"obs_noise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06399634337957093,\n        \"min\": 0.03,\n        \"max\": 0.35,\n        \"num_unique_values\": 805,\n        \"samples\": [\n          0.2358,\n          0.2112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resilience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27974419001310136,\n        \"min\": 0.4,\n        \"max\": 2.15,\n        \"num_unique_values\": 949,\n        \"samples\": [\n          1.4743,\n          1.0812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fatigue_sens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3196399410632579,\n        \"min\": 0.2587,\n        \"max\": 2.0,\n        \"num_unique_values\": 943,\n        \"samples\": [\n          1.2016,\n          0.4545\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rpe_report_bias\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35868778448000604,\n        \"min\": -1.1284,\n        \"max\": 1.0803,\n        \"num_unique_values\": 965,\n        \"samples\": [\n          -0.2024,\n          -0.3606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "LEVELS = [\"Beginner\", \"Intermediate\", \"Advanced\"]\n",
        "\n",
        "def sample_user_window(cfg: CFG, rng) -> tuple[date, date]:\n",
        "    end_date = cfg.today + timedelta(days=int(rng.integers(0, cfg.end_date_max_days_ahead + 1)))\n",
        "    dur = int(rng.integers(cfg.min_duration_days, cfg.max_duration_days + 1))\n",
        "    start_date = end_date - timedelta(days=dur)\n",
        "    return start_date, end_date\n",
        "\n",
        "def sample_user_latents(cfg: CFG, rng):\n",
        "    # experience_latent in [0,1], 0=novice-ish, 1=advanced-ish\n",
        "    exp_lat = float(np.clip(rng.beta(2.0, 2.0), 0.0, 1.0))\n",
        "\n",
        "    # Parametri continui\n",
        "    # adattamento: più alto per exp_lat bassa\n",
        "    alpha = float(np.clip(rng.normal(0.05 - 0.03*exp_lat, 0.01), 0.005, 0.08))\n",
        "    # detraining: più alto per exp_lat bassa\n",
        "    k_d = float(np.clip(rng.normal(0.020 - 0.012*exp_lat, 0.004), 0.002, 0.03))\n",
        "    # noise: più alto per exp_lat bassa\n",
        "    obs_noise = float(np.clip(rng.normal(0.25 - 0.18*exp_lat, 0.05), 0.03, 0.35))\n",
        "\n",
        "    resilience = float(np.clip(rng.normal(1.0 + 0.6*exp_lat, 0.25), 0.4, 2.2))\n",
        "    fatigue_sens = float(np.clip(rng.lognormal(mean=-0.2, sigma=0.35), 0.2, 2.0))\n",
        "\n",
        "    return dict(\n",
        "        experience_latent=exp_lat,\n",
        "        alpha_adapt=alpha,\n",
        "        k_detraining=k_d,\n",
        "        obs_noise=obs_noise,\n",
        "        resilience=resilience,\n",
        "        fatigue_sens=fatigue_sens,\n",
        "        rpe_report_bias=float(rng.normal(0.0, 0.35)),\n",
        "    )\n",
        "\n",
        "def latents_to_experience_label(exp_lat: float) -> str:\n",
        "    # discretizzazione semplice\n",
        "    # 3 classi: Beginner / Intermediate / Advanced\n",
        "    if exp_lat < 0.40:\n",
        "        return \"Beginner\"\n",
        "    if exp_lat < 0.80:\n",
        "        return \"Intermediate\"\n",
        "    return \"Advanced\"\n",
        "\n",
        "def generate_users(cfg: CFG, rng) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for uid in range(1, cfg.n_users + 1):\n",
        "        start_u, end_u = sample_user_window(cfg, rng)\n",
        "        weekly_freq = clamp_int(rng.normal(cfg.weekly_freq_mu, cfg.weekly_freq_sd),\n",
        "                                cfg.weekly_freq_min, cfg.weekly_freq_max)\n",
        "        split = sample_split(rng)\n",
        "\n",
        "        lat = sample_user_latents(cfg, rng)\n",
        "        exp_label = latents_to_experience_label(lat[\"experience_latent\"])\n",
        "\n",
        "        rows.append({\n",
        "            \"userid\": uid,\n",
        "            \"weeklyfreqdeclared\": weekly_freq,\n",
        "            \"splittype\": split,\n",
        "            \"start_date\": start_u.isoformat(),\n",
        "            \"end_date\": end_u.isoformat(),\n",
        "\n",
        "            # label target (non nei log)\n",
        "            \"experience_label\": exp_label,\n",
        "\n",
        "            # latenti\n",
        "            \"experience_latent\": round(lat[\"experience_latent\"], 4),\n",
        "            \"alpha_adapt\": round(lat[\"alpha_adapt\"], 5),\n",
        "            \"k_detraining\": round(lat[\"k_detraining\"], 5),\n",
        "            \"obs_noise\": round(lat[\"obs_noise\"], 4),\n",
        "            \"resilience\": round(lat[\"resilience\"], 4),\n",
        "            \"fatigue_sens\": round(lat[\"fatigue_sens\"], 4),\n",
        "            \"rpe_report_bias\": round(lat[\"rpe_report_bias\"], 4),\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "df_users = generate_users(cfg, rng)\n",
        "df_users.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf1oej6nFCjw"
      },
      "source": [
        "---\n",
        "#6. **Capabilities & Templates**\n",
        "\n",
        "Generazione capacità iniziali (cmax) e template sessioni.\n",
        "\n",
        "## **Capabilities (Cmax)**\n",
        "Per ogni (user, exercise): **carico massimale teorico**\n",
        "- Base = f(experience_label, experience_latent)\n",
        "- Moltiplicatore difficoltà esercizio (Beginner: 0.85×, Intermediate: 1.0×, Advanced: 1.12×)\n",
        "- Jitter individuale\n",
        "\n",
        " **Importante**: `cmax` **evolve dinamicamente**:\n",
        "- ↑ con progressive overload\n",
        "- ↓ con detraining (pause > 7 giorni)\n",
        "\n",
        "## **Templates Sessioni**\n",
        "\n",
        "### PPL Split (70% utenti)\n",
        "Rotazione: Push → Pull → Legs (3-6 esercizi/sessione)\n",
        "\n",
        "### FullBody Split (30% utenti)\n",
        "Rotazione: FullBody-A/B/C (mix bilanciato: 1 legs + 1 push + 1 pull + opzionale core)\n",
        "\n",
        "## Output\n",
        "- `caps`: dict `{userid: {exerciseid: cmax_kg}}`\n",
        "- `templates`: dict `{userid: {session_tag: [exerciseid, ...]}}`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsFmRqq5i6aD"
      },
      "source": [
        "**CELL 6 — (Python) Capabilities (cmax) + templates per split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikWIqn-aiPty",
        "outputId": "be58d2d1-bce8-4c31-d0c4-8f339d29ada2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, {'Push': [10, 8, 1, 4], 'Pull': [2, 11, 5], 'Legs': [12, 9, 3, 6]})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "BASEMAP = {\"Beginner\": 50.0, \"Intermediate\": 80.0, \"Advanced\": 105.0}\n",
        "\n",
        "def build_capabilities(df_users: pd.DataFrame, df_ex: pd.DataFrame, rng) -> dict:\n",
        "    caps = {}\n",
        "    for u in df_users.itertuples(index=False):\n",
        "        uid = int(u.userid)\n",
        "        exp_label = str(u.experience_label)\n",
        "        exp_lat = float(u.experience_latent)\n",
        "\n",
        "        # scala base da label (solo per cmax \"medio\"), ma con jitter continuo su exp_lat\n",
        "        # Nota: non stiamo usando la label per governare dinamiche; è solo un prior sul massimo teorico.\n",
        "        base_factor = BASEMAP.get(exp_label, 70.0) * (0.85 + 0.30*exp_lat)\n",
        "\n",
        "        usermap = {}\n",
        "        for ex in df_ex.itertuples(index=False):\n",
        "            # difficoltà esercizio influenza cmax relativo\n",
        "            diff = str(ex.difficultylevel)\n",
        "            diff_mul = {\"Beginner\": 0.85, \"Intermediate\": 1.0, \"Advanced\": 1.12}.get(diff, 1.0)\n",
        "            cmax = base_factor * diff_mul * float(rng.normal(1.0, 0.12))\n",
        "            cmax = float(np.clip(cmax, 10.0, 200.0))\n",
        "            usermap[int(ex.exerciseid)] = qload(cmax, cfg.load_step)\n",
        "        caps[uid] = usermap\n",
        "    return caps\n",
        "\n",
        "PPL_ROT = [\"Push\", \"Pull\", \"Legs\"]\n",
        "FB_ROT = [\"FullBody-A\", \"FullBody-B\", \"FullBody-C\"]\n",
        "\n",
        "def choose_exercises_for_tag(df_ex: pd.DataFrame, tag: str, rng, n_min=3, n_max=6):\n",
        "    if tag.startswith(\"FullBody\"):\n",
        "        pools = {\n",
        "            \"legs\": df_ex[df_ex[\"splitcat\"].isin([\"legs\"])],\n",
        "            \"push\": df_ex[df_ex[\"splitcat\"].isin([\"push\"])],\n",
        "            \"pull\": df_ex[df_ex[\"splitcat\"].isin([\"pull\"])],\n",
        "            \"core\": df_ex[df_ex[\"splitcat\"].isin([\"core\"])],\n",
        "            \"other\": df_ex[~df_ex[\"splitcat\"].isin([\"legs\",\"push\",\"pull\",\"core\"])],\n",
        "        }\n",
        "        exids = []\n",
        "        for k, n in [(\"legs\",1),(\"push\",1),(\"pull\",1)]:\n",
        "            if len(pools[k]) > 0:\n",
        "                exids += rng.choice(pools[k][\"exerciseid\"].values, size=n, replace=False).tolist()\n",
        "        if len(pools[\"core\"]) and rng.random() < 0.6:\n",
        "            exids += rng.choice(pools[\"core\"][\"exerciseid\"].values, size=1, replace=False).tolist()\n",
        "        while len(exids) < 4:\n",
        "            pool = pools[\"other\"] if len(pools[\"other\"]) else df_ex\n",
        "            exids += rng.choice(pool[\"exerciseid\"].values, size=1, replace=False).tolist()\n",
        "        # dedup mantenendo ordine\n",
        "        seen = set()\n",
        "        exids2 = []\n",
        "        for x in exids:\n",
        "            if x not in seen:\n",
        "                seen.add(x)\n",
        "                exids2.append(int(x))\n",
        "        return exids2[:6]\n",
        "\n",
        "    # PPL\n",
        "    tag_l = tag.lower()\n",
        "    pool = df_ex[df_ex[\"splitcat\"] == tag_l]\n",
        "    if len(pool) < 3:\n",
        "        pool = df_ex.copy()\n",
        "    n = int(rng.integers(n_min, n_max + 1))\n",
        "    n = min(n, len(pool))\n",
        "    return [int(x) for x in rng.choice(pool[\"exerciseid\"].values, size=n, replace=False)]\n",
        "\n",
        "def build_user_templates(df_users, df_ex, rng):\n",
        "    templates = {}\n",
        "    for u in df_users.itertuples(index=False):\n",
        "        uid = int(u.userid)\n",
        "        split = str(u.splittype)\n",
        "        tags = PPL_ROT if split == \"PPL\" else FB_ROT\n",
        "        templates[uid] = {tag: choose_exercises_for_tag(df_ex, tag, rng) for tag in tags}\n",
        "    return templates\n",
        "\n",
        "caps = build_capabilities(df_users, df_ex, rng)\n",
        "templates = build_user_templates(df_users, df_ex, rng)\n",
        "\n",
        "list(templates.items())[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Zy7hUYFCjw"
      },
      "source": [
        "---\n",
        "#7. **Prescription Helpers**\n",
        "\n",
        "Funzioni per prescrivere parametri allenamento.\n",
        "\n",
        "## `prescribe_exercise()`\n",
        "Genera prescrizione basata su difficoltà esercizio + esperienza utente.\n",
        "\n",
        "### **Range per Difficoltà Esercizio**\n",
        "\n",
        "| Parametro | Beginner Ex | Intermediate Ex | Advanced Ex |\n",
        "|-----------|-------------|-----------------|-------------|\n",
        "| Sets | 2-4 | 3-5 | 3-6 |\n",
        "| Reps (mid) | ~12 | ~8 | ~6 |\n",
        "| Rest (sec) | 60-120 | 90-180 | 120-240 |\n",
        "\n",
        "**RIR target** dipende da esperienza utente:\n",
        "- Beginner user → RIR ~2.5 (buffer sicurezza)\n",
        "- Intermediate → RIR ~2.0\n",
        "- Advanced → RIR ~1.5 (vicinanza cedimento)\n",
        "\n",
        "## `intensity_from_reps_rir()`\n",
        "Euristica intensità (% cmax) da reps + RIR:\n",
        "```\n",
        "intensity = 0.86 - 0.018*(reps - 5) - 0.03*rir + noise\n",
        "```\n",
        "\n",
        "Esempi:\n",
        "- 5 reps, RIR 1 → ~83% (forza)\n",
        "- 12 reps, RIR 2.5 → ~65% (ipertrofia)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQf8GEsui94U"
      },
      "source": [
        "**CELL 7 — (Python) Plan prescription (per esercizio) + helpers intensità**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xU2bkt4jBj2"
      },
      "outputs": [],
      "source": [
        "def prescribe_exercise(df_ex_row: dict, experience_label: str, rng):\n",
        "    # Range reps/sets/rest/rir per esercizio (semplice e stabile)\n",
        "    lvl = str(df_ex_row[\"difficultylevel\"])\n",
        "\n",
        "    # default base su difficoltà esercizio (non su esperienza!)\n",
        "    if lvl == \"Beginner\":\n",
        "        reps_mu, reps_sd = 12, 2\n",
        "        sets_lo, sets_hi = 2, 4\n",
        "        rest_lo, rest_hi = 60, 120\n",
        "    elif lvl == \"Intermediate\":\n",
        "        reps_mu, reps_sd = 8, 2\n",
        "        sets_lo, sets_hi = 3, 5\n",
        "        rest_lo, rest_hi = 90, 180\n",
        "    else:  # Advanced/altro\n",
        "        reps_mu, reps_sd = 6, 2\n",
        "        sets_lo, sets_hi = 3, 6\n",
        "        rest_lo, rest_hi = 120, 240\n",
        "\n",
        "    # RIR target può dipendere dall'esperienza (scelta coaching), ma non entra come \"flag di dinamica\"\n",
        "    # (serve per definire la prescrizione, che è osservabile nel plan)\n",
        "    if experience_label in [\"Beginner\", \"Novice\"]:\n",
        "        rir_mu = 2.5\n",
        "    elif experience_label == \"Intermediate\":\n",
        "        rir_mu = 2.0\n",
        "    else:\n",
        "        rir_mu = 1.5\n",
        "\n",
        "    setsplanned = int(rng.integers(sets_lo, sets_hi + 1))\n",
        "    repsmid = clamp_int(rng.normal(reps_mu, reps_sd), 3, 20)\n",
        "    width = 2 if lvl != \"Beginner\" else 3\n",
        "    repsmin = max(1, repsmid - width)\n",
        "    repsmax = min(30, repsmid + width)\n",
        "\n",
        "    restplannedsec = int(rng.integers(rest_lo, rest_hi + 1))\n",
        "    rirtarget = clamp_int(rng.normal(rir_mu, 0.6), 0, 5)\n",
        "\n",
        "    return setsplanned, repsmin, repsmax, restplannedsec, rirtarget\n",
        "\n",
        "def intensity_from_reps_rir(reps_target: float, rir_target: float, rng):\n",
        "    # euristica: più reps e più RIR => intensità minore\n",
        "    base = 0.86 - 0.018*(reps_target - 5.0) - 0.03*rir_target\n",
        "    base += float(rng.normal(0.0, 0.02))\n",
        "    return float(np.clip(base, 0.35, 0.92))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXBoUrwLFCjx"
      },
      "source": [
        "---\n",
        "#8. **Core Simulation Engine**\n",
        "\n",
        "**Cuore del generatore**: simulazione dinamica per singolo utente.\n",
        "\n",
        "## **Flusso Simulazione**\n",
        "\n",
        "### 1. **Inizializzazione**\n",
        "- Fitness, fatigue, skill iniziali\n",
        "- Parametri Banister individuali (tauF, tauD)\n",
        "- Capacità iniziali per esercizio (copiate da `caps_u`, evolveranno)\n",
        "\n",
        "### 2. **Schedule Sessioni**\n",
        "- Date candidate da `weeklyfreqdeclared`\n",
        "- Jitter realistico (±1 giorno)\n",
        "\n",
        "### 3. **Loop Giornaliero**\n",
        "\n",
        "Per ogni data schedulata:\n",
        "\n",
        "#### A. Detraining (se gap > 1 giorno)\n",
        "```python\n",
        "fitness *= exp(-k_d * gap)\n",
        "# Se gap > 7: decay anche capacità\n",
        "```\n",
        "\n",
        "#### B. Decay Fatica\n",
        "```python\n",
        "fatigue *= exp(-1/7)  # ~1 settimana per dimezzare\n",
        "```\n",
        "\n",
        "#### C. Skip Decision\n",
        "Modello logistico:\n",
        "```python\n",
        "p_skip = sigmoid(bias_livello + weight*fatigue + noise)\n",
        "```\n",
        "- Baseline: Beginner 10%, Intermediate 6.5%, Advanced 5%\n",
        "- Fatica aumenta probabilità\n",
        "\n",
        "#### D. Esecuzione Sessione (se non skip)\n",
        "Per ogni esercizio:\n",
        "1. **Prescrizione**: setsplanned, reps range, RIR\n",
        "2. **Esecuzione serie**: per ogni set:\n",
        "   ```python\n",
        "   load_done = intensity * cmax * (1 - fatigue_penalty) + noise\n",
        "   reps_done ~ reps_target * (1 - 0.2*fatigue_factor) + noise\n",
        "   RPE = 4 + 5.5*intensity + 1.8*rep_gap + 1.2*fatigue + bias\n",
        "   ```\n",
        "   - Penalità fatica **ridotta per Beginner** (80% in meno) → newbie gains\n",
        "3. **Impulso Banister**: `impulse += load * reps * (RPE/10)`\n",
        "4. **Fatica intra-sessione**: aumenta progressivamente\n",
        "\n",
        "#### E. **Progressive Overload (post-sessione)**\n",
        "```python\n",
        "stim = clip(impulse / I0, 0.05, 2.0)\n",
        "quality = max(0.2, 1 - 0.6*(fatigue/20))\n",
        "gain_base = growth_rate * stim * quality\n",
        "```\n",
        "\n",
        "**Transfer tra esercizi**:\n",
        "- Allenato direttamente: 100%\n",
        "- Stesso targetmusclegroup: 35%\n",
        "- Stesso splitcat: 12%\n",
        "- Nessuna similitudine: 0%\n",
        "\n",
        "```python\n",
        "current_caps[eid] *= (1 + gain_base * transfer_weight)\n",
        "```\n",
        "\n",
        "#### F. **Injury Event**\n",
        "```python\n",
        "p_injury = lambda * (impulse / resilience) * (1 + 0.5*fatigue_sens)\n",
        "```\n",
        "Se injury → volume ridotto (60%) fino a recovery.\n",
        "\n",
        "#### G. **Update Stato Globale**\n",
        "```python\n",
        "fitness += alpha * log1p(volume_proxy)\n",
        "skill += 0.002 * log1p(1 + exp_lat)\n",
        "fatigue = fatigue_session\n",
        "```\n",
        "\n",
        "## **Output per Utente**\n",
        "- `workouts_rows`: metadata sessioni\n",
        "- `plan_rows`: prescrizioni\n",
        "- `sets_rows`: log dettagliato set-level\n",
        "- `impulse_rows`: impulso giornaliero\n",
        "- `user_meta`: parametri Banister\n",
        "\n",
        "---\n",
        "\n",
        " **Complessità**: O(n_users × n_sessions × n_exercises × n_sets)\n",
        "\n",
        "300 utenti × 200 sessioni × 4 esercizi × 4 set ≈ **1M righe**\n",
        "\n",
        " Tempo: ~5-8 minuti CPU standard.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f25VNy0ajC14"
      },
      "source": [
        "**CELL 8 — (Python) Scheduler per utente + simulazione set-level (core)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNQf1dvljGCM"
      },
      "outputs": [],
      "source": [
        "def schedule_sessions_for_user(start_u: date, end_u: date, weekly_freq: int, rng):\n",
        "    # giorni target della settimana\n",
        "    basedays = sorted(rng.choice(np.arange(7), size=weekly_freq, replace=False).tolist())\n",
        "    dates = []\n",
        "    d0 = start_u\n",
        "    n_days = (end_u - start_u).days + 1\n",
        "    for i in range(n_days):\n",
        "        day = d0 + timedelta(days=i)\n",
        "        if day.weekday() in basedays:\n",
        "            # jitter -1/0/+1\n",
        "            jitter = int(rng.choice([-1,0,1], p=cfg.weekday_jitter_probs))\n",
        "            day2 = day + timedelta(days=jitter)\n",
        "            if start_u <= day2 <= end_u:\n",
        "                dates.append(day2)\n",
        "    dates = sorted(list(set(dates)))\n",
        "    return dates\n",
        "\n",
        "def simulate_user(cfg: CFG, user_row: dict, df_ex: pd.DataFrame, caps_u: dict, templates_u: dict, rng):\n",
        "    uid = int(user_row[\"userid\"])\n",
        "    start_u = date.fromisoformat(user_row[\"start_date\"])\n",
        "    end_u = date.fromisoformat(user_row[\"end_date\"])\n",
        "    weekly_freq = int(user_row[\"weeklyfreqdeclared\"])\n",
        "    experience_label = str(user_row[\"experience_label\"])\n",
        "\n",
        "    # latenti (stato + parametri)\n",
        "    exp_lat = float(user_row[\"experience_latent\"])\n",
        "    alpha = float(user_row[\"alpha_adapt\"])\n",
        "    k_d = float(user_row[\"k_detraining\"])\n",
        "    obs_noise = float(user_row[\"obs_noise\"])\n",
        "    resilience = float(user_row[\"resilience\"])\n",
        "    fatigue_sens = float(user_row[\"fatigue_sens\"])\n",
        "    rpe_bias = float(user_row[\"rpe_report_bias\"])\n",
        "\n",
        "    # Banister params per utente\n",
        "    tauF = float(max(7.0, rng.normal(cfg.tauF_mean, cfg.tauF_sd)))\n",
        "    tauD = float(max(2.0, rng.normal(cfg.tauD_mean, cfg.tauD_sd)))\n",
        "\n",
        "    # stato dinamico (scalari)\n",
        "    fitness = float(rng.normal(0.0, 1.0))\n",
        "    fatigue = float(max(0.0, rng.normal(0.5, 0.3)))\n",
        "    skill = float(np.clip(rng.normal(0.2 + 0.6*exp_lat, 0.15), 0.0, 2.0))\n",
        "\n",
        "    # injury state\n",
        "    injury_until = None\n",
        "\n",
        "    # schedule “candidato”\n",
        "    session_dates = schedule_sessions_for_user(start_u, end_u, weekly_freq, rng)\n",
        "\n",
        "    workouts_rows = []\n",
        "    plan_rows = []\n",
        "    sets_rows = []\n",
        "    impulse_rows = []\n",
        "\n",
        "    wid = 1  # per-user counter, poi lo rendiamo globale fuori\n",
        "    set_id_counter = 1\n",
        "\n",
        "    # rotazione tag per split\n",
        "    tags = PPL_ROT if str(user_row[\"splittype\"]) == \"PPL\" else FB_ROT\n",
        "    tag_i = int(rng.integers(0, len(tags)))\n",
        "\n",
        "    last_train_date = None\n",
        "\n",
        "    # --- PROGRESSIVE OVERLOAD STATE ---\n",
        "    # Copia dinamica delle capacità (evolveranno nel tempo)\n",
        "    current_caps = {eid: float(val) for eid, val in caps_u.items()}\n",
        "\n",
        "    # Tasso crescita personale\n",
        "    base_growth = cfg.overload_base_rate.get(experience_label, 0.001)\n",
        "    growth_rate = float(np.clip(rng.normal(base_growth, 0.0002), 1e-5, 0.005))\n",
        "\n",
        "\n",
        "    for d in session_dates:\n",
        "        # detraining: se gap\n",
        "        if last_train_date is not None:\n",
        "            gap = (d - last_train_date).days\n",
        "            if gap > 1:\n",
        "                fitness *= math.exp(-k_d * gap)\n",
        "\n",
        "                    # Detraining anche su capacità se gap molto lungo (>7 giorni)\n",
        "                    # if gap > 7:\n",
        "                    #     decay = math.exp(-k_d * (gap - 7) * 0.3)\n",
        "                    #     for eid in current_caps:\n",
        "                    #         current_caps[eid] *= decay\n",
        "\n",
        "\n",
        "        # decay fatica giornaliero\n",
        "        fatigue *= math.exp(-1.0/7.0)\n",
        "\n",
        "\n",
        "        # se infortunio\n",
        "        in_injury = (injury_until is not None and d <= injury_until)\n",
        "\n",
        "\n",
        "\n",
        "        # skip probability\n",
        "        # --- SKIP MODEL (baseline per livello + fatica leggera) ---\n",
        "        p0 = float(cfg.skip_p0_by_level.get(experience_label, 0.10))\n",
        "        bias = logit(p0)\n",
        "\n",
        "        fat_term = float(np.log1p(max(0.0, float(fatigue))))\n",
        "        fat_term = min(fat_term, float(cfg.skip_fatigue_cap))\n",
        "\n",
        "        z = bias + float(cfg.skip_fatigue_weight) * fat_term + float(rng.normal(0.0, cfg.skip_noise_sd))\n",
        "        p_skip = sigmoid(z)\n",
        "\n",
        "        status = \"done\"\n",
        "        if rng.random() < p_skip:\n",
        "            status = \"skipped\"\n",
        "        # ----------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "        # assegna tag sessione\n",
        "        tag = tags[tag_i % len(tags)]\n",
        "        tag_i += 1\n",
        "\n",
        "        week_index_user = (d - start_u).days // 7 + 1\n",
        "\n",
        "        workouts_rows.append({\n",
        "            \"userid\": uid,\n",
        "            \"date\": d.isoformat(),\n",
        "            \"weekindex_user\": int(week_index_user),\n",
        "            \"sessiontag\": tag,\n",
        "            \"workoutstatus\": status,\n",
        "            \"z_skip\": float(z),\n",
        "            \"p_skip\": float(p_skip),\n",
        "            \"fatigue_term\": float(fat_term),\n",
        "            \"experience_label\": experience_label,\n",
        "        })\n",
        "\n",
        "        if status == \"skipped\":\n",
        "            impulse_rows.append({\"userid\": uid, \"date\": d.isoformat(), \"impulse\": 0.0})\n",
        "            continue\n",
        "\n",
        "        # plan per esercizio (per questa sessione)\n",
        "        exids = templates_u.get(tag, [])\n",
        "        if len(exids) == 0:\n",
        "            exids = templates_u[list(templates_u.keys())[0]]\n",
        "\n",
        "        # fatica intra-sessione (scalare semplice)\n",
        "        fatigue_session = float(fatigue)\n",
        "\n",
        "        day_impulse = 0.0\n",
        "        day_total_sets = 0\n",
        "\n",
        "        for exid in exids:\n",
        "            exrow = df_ex[df_ex[\"exerciseid\"] == exid].iloc[0].to_dict()\n",
        "            setsplanned, repsmin, repsmax, restplannedsec, rirtarget = prescribe_exercise(exrow, experience_label, rng)\n",
        "\n",
        "            # eventuale riduzione volume in injury\n",
        "            if in_injury:\n",
        "                setsplanned = max(1, int(round(setsplanned * 0.6)))\n",
        "\n",
        "            plan_rows.append({\n",
        "                \"userid\": uid,\n",
        "                \"date\": d.isoformat(),\n",
        "                \"sessiontag\": tag,\n",
        "                \"exerciseid\": int(exid),\n",
        "                \"setsplanned\": int(setsplanned),\n",
        "                \"repsmin\": int(repsmin),\n",
        "                \"repsmax\": int(repsmax),\n",
        "                \"restplannedsec\": int(restplannedsec),\n",
        "                \"rirtarget\": int(rirtarget),\n",
        "            })\n",
        "\n",
        "            # Usa capacità CORRENTE (dinamica)\n",
        "            cmax = current_caps.get(int(exid), 50.0)\n",
        "\n",
        "            # intended baseline load (per esercizio) dalla prima serie\n",
        "            reps_target0 = int(rng.integers(repsmin, repsmax + 1))\n",
        "            inten0 = intensity_from_reps_rir(reps_target0, rirtarget, rng)\n",
        "            intended_load = qload(inten0 * cmax, cfg.load_step)\n",
        "\n",
        "            # “esecuzione”: setdone ~ setsplanned con rumore/aderenza implicita\n",
        "            setsdone = int(np.clip(round(rng.normal(setsplanned, 0.5)), 1, 10))\n",
        "\n",
        "            for s in range(1, setsdone + 1):\n",
        "                day_total_sets += 1\n",
        "\n",
        "                reps_target = int(rng.integers(repsmin, repsmax + 1))\n",
        "                inten = intensity_from_reps_rir(reps_target, rirtarget, rng)\n",
        "\n",
        "                fatigue_factor = float(np.clip(0.03 * fatigue_session * fatigue_sens, 0.0, 0.20))\n",
        "\n",
        "                # Riduzione fatica per Beginner (per permettere newbie gains)\n",
        "                if experience_label == \"Beginner\":\n",
        "                    fatigue_factor *= 0.2  # riduce dell'80% (era 70%)\n",
        "\n",
        "\n",
        "\n",
        "                load_done = float(inten * cmax * (1.0 - fatigue_factor))\n",
        "                load_done *= float(rng.normal(1.0, 0.03 + obs_noise*0.08))\n",
        "                load_done = qload(float(np.clip(load_done, 2.5, cmax)), cfg.load_step)\n",
        "\n",
        "                # reps calano se fatica sale\n",
        "                reps_done = int(np.clip(round(rng.normal(reps_target * (1.0 - 0.20*fatigue_factor), 0.6 + obs_noise*1.5)),\n",
        "                                        1, 30))\n",
        "\n",
        "                # RPE cresce con intensità e fatica e gap reps\n",
        "                rep_gap = (reps_target - reps_done) / max(1.0, reps_target)\n",
        "                rpe_true = 4.0 + 5.5*inten + 1.8*rep_gap + 1.2*fatigue_factor\n",
        "                rpe_obs = float(rng.normal(rpe_true + rpe_bias, 0.35 + obs_noise))\n",
        "                rpe_done = qrpe(rpe_obs, cfg.rpe_step)\n",
        "\n",
        "                # feedback raro\n",
        "                feedback = None\n",
        "                if rng.random() < 0.03:\n",
        "                    feedback = str(rng.choice([\n",
        "                        \"Tecnica ok\", \"Fatica alta\", \"Allenamento solido\", \"Recuperi corti\", \"Non ero in giornata\"\n",
        "                    ]))\n",
        "\n",
        "                # missingness (solo osservazioni)\n",
        "                if rng.random() < cfg.p_missing_rpe:\n",
        "                    rpe_done = np.nan\n",
        "                if rng.random() < cfg.p_missing_load:\n",
        "                    load_done = np.nan\n",
        "                if rng.random() < cfg.p_missing_feedback:\n",
        "                    feedback = None\n",
        "\n",
        "                sets_rows.append({\n",
        "                    \"set_id\": f\"U{uid:04d}_S{set_id_counter:07d}\",\n",
        "                    \"userid\": uid,\n",
        "                    \"date\": d.isoformat(),\n",
        "                    \"weekindex_user\": int(week_index_user),\n",
        "                    \"sessiontag\": tag,\n",
        "                    \"exerciseid\": int(exid),\n",
        "\n",
        "                    \"set_index\": int(s),\n",
        "\n",
        "                    \"reps_target\": int(reps_target),\n",
        "                    \"reps_done\": int(reps_done),\n",
        "                    \"load_intended_kg\": float(intended_load),\n",
        "                    \"load_done_kg\": load_done,\n",
        "                    \"rpe_done\": rpe_done,\n",
        "\n",
        "                    \"restplannedsec\": int(restplannedsec),\n",
        "                    \"rirtarget\": int(rirtarget),\n",
        "                    \"feedback\": feedback,\n",
        "                })\n",
        "                set_id_counter += 1\n",
        "\n",
        "                # impulso giornaliero (Banister input)\n",
        "                ld = 0.0 if (isinstance(load_done, float) and np.isnan(load_done)) else float(load_done)\n",
        "                rd = 0.0 if (isinstance(rpe_done, float) and np.isnan(rpe_done)) else float(rpe_done)\n",
        "                day_impulse += ld * float(reps_done) * (rd / 10.0)\n",
        "\n",
        "                # aggiorna fatica intra-sessione\n",
        "                fatigue_session += 0.08 * inten + 0.02 * (ld / max(20.0, cmax))\n",
        "\n",
        "            # aggiorna fitness/fatica/skill post-esercizio (molto semplice)\n",
        "            # carico “effettivo” = intended * volume relativo\n",
        "            vol_proxy = setsdone * reps_target0 * float(intended_load)\n",
        "            fitness += alpha * math.log1p(vol_proxy / 1000.0)\n",
        "            skill += 0.002 * math.log1p(1.0 + exp_lat)  # crescita lenta\n",
        "\n",
        "\n",
        "        # --- APPLICA PROGRESSIVE OVERLOAD (dose-driven + transfer) ---\n",
        "        if status == \"done\" and day_impulse > 5.0 and not in_injury:\n",
        "            # Stimolo normalizzato (saturato a 2x)\n",
        "            stim = float(np.clip(day_impulse / cfg.overload_I0, 0.05, 2.0))\n",
        "\n",
        "            # Quality factor: scende con fatica alta\n",
        "            quality = max(0.2, 1.0 - cfg.overload_quality_fatigue * (fatigue / 20.0))\n",
        "\n",
        "            # Guadagno base per questa sessione\n",
        "            gain_base = growth_rate * stim * quality\n",
        "\n",
        "            # Transfer: itera su TUTTI gli esercizi e applica peso per similitudine\n",
        "            exids_done_set = set(exids)  # esercizi fatti oggi\n",
        "\n",
        "            for ex_target in df_ex.itertuples(index=False):\n",
        "                eid_target = int(ex_target.exerciseid)\n",
        "\n",
        "                # Calcola peso transfer\n",
        "                if eid_target in exids_done_set:\n",
        "                    # Esercizio allenato direttamente\n",
        "                    weight = 1.00\n",
        "                else:\n",
        "                    # Transfer indiretto (basato su similitudine)\n",
        "                    weight = 0.0\n",
        "\n",
        "                    # Controlla similitudine con ciascuno degli esercizi fatti\n",
        "                    for eid_done in exids_done_set:\n",
        "                        ex_done_row = df_ex[df_ex[\"exerciseid\"] == eid_done].iloc[0]\n",
        "\n",
        "                        # Stesso targetmusclegroup (specifico)\n",
        "                        if str(ex_target.targetmusclegroup).lower() == str(ex_done_row[\"targetmusclegroup\"]).lower():\n",
        "                            weight = max(weight, cfg.transfer_same_muscle)\n",
        "                        # Stesso splitcat (pattern motorio simile)\n",
        "                        elif str(ex_target.splitcat).lower() == str(ex_done_row[\"splitcat\"]).lower():\n",
        "                            weight = max(weight, cfg.transfer_same_split)\n",
        "\n",
        "                            # DEBUG: verifica crescita per User 1 (Advanced che calava)\n",
        "                            if uid == 1:\n",
        "                                cap_ex9_new = current_caps.get(9, 0)\n",
        "                                print(f\"[DEBUG] User {uid} Day {d.isoformat()}: Impulse={day_impulse:.1f}, Stim={stim:.3f}, Quality={quality:.3f}, GainBase={gain_base:.5f}\")\n",
        "                                print(f\"         Cap Ex9 → {cap_ex9_new:.2f} kg\")\n",
        "\n",
        "                # Applica adattamento\n",
        "                if weight > 0:\n",
        "                    gain = gain_base * weight\n",
        "                    current_caps[eid_target] = float(current_caps.get(eid_target, 50.0) * (1.0 + gain))\n",
        "\n",
        "\n",
        "        # injury event (dopo sessione): aumenta con fatica e “impulso” e bassa resilienza\n",
        "        p_injury = cfg.injury_lambda * (day_impulse / max(1.0, resilience)) * (1.0 + 0.5*fadigue_sens if (fadigue_sens:=fatigue_sens) else 1.0)\n",
        "        p_injury = float(np.clip(p_injury, 0.0, 0.35))\n",
        "        if (injury_until is None or d > injury_until) and rng.random() < p_injury:\n",
        "            injury_days = int(rng.integers(cfg.injury_days_min, cfg.injury_days_max + 1))\n",
        "            injury_until = d + timedelta(days=injury_days)\n",
        "\n",
        "        # aggiorna fatica globale a fine sessione\n",
        "        fatigue = float(np.clip(fatigue_session, 0.0, 20.0))\n",
        "\n",
        "        impulse_rows.append({\"userid\": uid, \"date\": d.isoformat(), \"impulse\": float(day_impulse)})\n",
        "        last_train_date = d\n",
        "\n",
        "    # output user-level metadata Banister\n",
        "    user_meta = {\n",
        "        \"userid\": uid,\n",
        "        \"tauF\": tauF,\n",
        "        \"tauD\": tauD,\n",
        "        \"betaF\": cfg.betaF,\n",
        "        \"betaD\": cfg.betaD\n",
        "    }\n",
        "\n",
        "    return workouts_rows, plan_rows, sets_rows, impulse_rows, user_meta\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9o3nDxXFCjx"
      },
      "source": [
        "### **Test Detraining Logic**\n",
        "\n",
        "Verifica decay capacità durante pause lunghe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG7dlXOjDyhW",
        "outputId": "fa546127-1b05-4b5b-f585-feb2ca3ab42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifica che current_caps esista e sia modificabile:\n",
            "  Decay factor per gap=10: 0.9910\n",
            "  Caps after: {1: 99.10403787728836, 2: 79.28323030183068}\n",
            "  (Dovrebbe essere ~99 e ~79, non 100 e 80)\n"
          ]
        }
      ],
      "source": [
        "# === TEST DETRAINING ===\n",
        "print(\"Verifica che current_caps esista e sia modificabile:\")\n",
        "test_caps = {1: 100.0, 2: 80.0}\n",
        "k_d_test = 0.01\n",
        "gap_test = 10\n",
        "\n",
        "if gap_test > 7:\n",
        "    decay = math.exp(-k_d_test * (gap_test - 7) * 0.3)\n",
        "    for eid in test_caps:\n",
        "        test_caps[eid] *= decay\n",
        "\n",
        "print(f\"  Decay factor per gap={gap_test}: {decay:.4f}\")\n",
        "print(f\"  Caps after: {test_caps}\")\n",
        "print(\"  (Dovrebbe essere ~99 e ~79, non 100 e 80)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwkNT6R4FCjx"
      },
      "source": [
        "---\n",
        "#9. **Run Generator (All Users)**\n",
        "\n",
        "Esecuzione simulazione per tutti gli utenti.\n",
        "\n",
        "## **Processo**\n",
        "1. Loop su tutti gli utenti in `df_users`\n",
        "2. Per ogni utente:\n",
        "   - `simulate_user()` → workouts, plan, sets, impulse\n",
        "   - Assegna `workoutid` **globale** univoco\n",
        "   - Mapping `(userid, date) → workoutid`\n",
        "   - Propaga `workoutid` a plan/sets\n",
        "3. Concatena DataFrame globali\n",
        "\n",
        "## **Output Globali**\n",
        "- `df_workouts`: workout metadata\n",
        "- `df_plan`: prescrizioni\n",
        "- `df_sets`: **set logs (principale)**\n",
        "- `df_impulse`: impulsi giornalieri\n",
        "- `df_ban_meta`: parametri Banister user\n",
        "\n",
        "---\n",
        "\n",
        " **Questa cella richiede diversi minuti**.\n",
        "\n",
        " Durante esecuzione: print debug User 1 (verifica progressive overload).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS6axoF_jHnO"
      },
      "source": [
        "**CELL 9 — (Python) Run generator (tutti utenti) + IDs globali**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFCZb7CrjLnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74889d91-4c3a-4e76-bef0-f59c8fd521a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   userid        date  weekindex_user sessiontag workoutstatus    z_skip  \\\n",
              " 0       1  2024-09-06               1       Push          done -2.188516   \n",
              " 1       1  2024-09-10               1       Pull          done -1.910497   \n",
              " 2       1  2024-09-13               2       Legs          done -1.968734   \n",
              " 3       1  2024-09-14               2       Push          done -2.067860   \n",
              " 4       1  2024-09-16               2       Pull          done -1.956130   \n",
              " \n",
              "      p_skip  fatigue_term experience_label  workoutid  \n",
              " 0  0.100786      0.003221         Beginner          1  \n",
              " 1  0.128925      0.502959         Beginner          2  \n",
              " 2  0.122525      0.739271         Beginner          3  \n",
              " 3  0.112260      1.025749         Beginner          4  \n",
              " 4  0.123886      1.150986         Beginner          5  ,\n",
              "            set_id  userid        date  weekindex_user sessiontag  exerciseid  \\\n",
              " 0  U0001_S0000001       1  2024-09-06               1       Push          10   \n",
              " 1  U0001_S0000002       1  2024-09-06               1       Push          10   \n",
              " 2  U0001_S0000003       1  2024-09-06               1       Push          10   \n",
              " 3  U0001_S0000004       1  2024-09-06               1       Push           8   \n",
              " 4  U0001_S0000005       1  2024-09-06               1       Push           1   \n",
              " \n",
              "    set_index  reps_target  reps_done  load_intended_kg  load_done_kg  \\\n",
              " 0          1            7          6             22.50         25.25   \n",
              " 1          2            9         10             22.50         23.00   \n",
              " 2          3            9          9             22.50         22.25   \n",
              " 3          1           12         12             28.50         29.00   \n",
              " 4          1           13         13             33.25         31.25   \n",
              " \n",
              "    rpe_done  restplannedsec  rirtarget        feedback  workoutid  \n",
              " 0       7.0             151          4            None          1  \n",
              " 1       6.5             151          4            None          1  \n",
              " 2       8.0             151          4            None          1  \n",
              " 3       7.0              68          2  Recuperi corti          1  \n",
              " 4       6.5             136          2            None          1  )"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "all_workouts = []\n",
        "all_plan = []\n",
        "all_sets = []\n",
        "all_impulse = []\n",
        "ban_meta_rows = []\n",
        "\n",
        "workout_id_counter = 1\n",
        "\n",
        "for u in df_users.to_dict(orient=\"records\"):\n",
        "    uid = int(u[\"userid\"])\n",
        "    w_rows, p_rows, s_rows, i_rows, meta = simulate_user(cfg, u, df_ex, caps[uid], templates[uid], rng)\n",
        "    ban_meta_rows.append(meta)\n",
        "\n",
        "    # assegna workout_id globale: stesso id per stessa (userid,date)\n",
        "    # costruisco mapping per user\n",
        "    wdf = pd.DataFrame(w_rows)\n",
        "    if len(wdf) == 0:\n",
        "        continue\n",
        "\n",
        "    # sort e assegnazione\n",
        "    wdf = wdf.sort_values([\"userid\",\"date\"]).reset_index(drop=True)\n",
        "    wdf[\"workoutid\"] = np.arange(workout_id_counter, workout_id_counter + len(wdf))\n",
        "    workout_id_counter += len(wdf)\n",
        "\n",
        "    # mapping (userid,date) -> workoutid\n",
        "    key_to_wid = {(int(r.userid), str(r.date)): int(r.workoutid) for r in wdf.itertuples(index=False)}\n",
        "\n",
        "    # push workouts\n",
        "    all_workouts.append(wdf)\n",
        "\n",
        "    # attach workoutid to plan/sets\n",
        "    pdf = pd.DataFrame(p_rows)\n",
        "    if len(pdf):\n",
        "        pdf[\"workoutid\"] = [key_to_wid[(int(r[\"userid\"]), str(r[\"date\"]))] for r in pdf.to_dict(\"records\")]\n",
        "        all_plan.append(pdf)\n",
        "\n",
        "    sdf = pd.DataFrame(s_rows)\n",
        "    if len(sdf):\n",
        "        sdf[\"workoutid\"] = [key_to_wid[(int(r[\"userid\"]), str(r[\"date\"]))] for r in sdf.to_dict(\"records\")]\n",
        "        all_sets.append(sdf)\n",
        "\n",
        "    idf = pd.DataFrame(i_rows)\n",
        "    if len(idf):\n",
        "        all_impulse.append(idf)\n",
        "\n",
        "df_workouts = pd.concat(all_workouts, ignore_index=True) if all_workouts else pd.DataFrame()\n",
        "df_plan = pd.concat(all_plan, ignore_index=True) if all_plan else pd.DataFrame()\n",
        "df_sets = pd.concat(all_sets, ignore_index=True) if all_sets else pd.DataFrame()\n",
        "df_impulse = pd.concat(all_impulse, ignore_index=True) if all_impulse else pd.DataFrame()\n",
        "df_ban_meta = pd.DataFrame(ban_meta_rows)\n",
        "\n",
        "df_workouts.head(), df_sets.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGOkAxQsFCjx"
      },
      "source": [
        "---\n",
        "# 10. **Derive Aggregated Views**\n",
        "\n",
        "Creazione viste aggregate da set-level.\n",
        "\n",
        "## **Workout Logs (Exercise-Level)**\n",
        "Aggregazione per (workoutid, userid, date, sessiontag, exerciseid).\n",
        "\n",
        "### **Metriche**\n",
        "- `setsdone`: max(set_index)\n",
        "- `repsdonetotal`: sum(reps_done)\n",
        "- `repsdoneavg`: mean(reps_done)\n",
        "- `loaddonekg`: median(load_done_kg)\n",
        "- `rpedone`: mean(rpe_done)\n",
        "\n",
        "### **GAP (Gap Adherence Score)**\n",
        "Aderenza al piano:\n",
        "```python\n",
        "GAP = 0.45*(load_done/load_intended) +\n",
        "      0.30*(sets_done/sets_planned) +\n",
        "      0.25*(reps_done/reps_target)\n",
        "```\n",
        "- GAP ~ 1.0: aderenza perfetta\n",
        "- GAP > 1.0: superamento piano\n",
        "- GAP < 1.0: sotto-esecuzione\n",
        "\n",
        "## **Sessions (Session-Level)**\n",
        "Aggregazione per (workoutid, userid, date, sessiontag).\n",
        "\n",
        "### **Metriche**\n",
        "- `total_sets`: count\n",
        "- `total_reps`: sum\n",
        "- `volume_kg`: sum(load × reps)\n",
        "- `sRPE`: mean(rpe_done)\n",
        "\n",
        "---\n",
        "\n",
        " **Uso**:\n",
        "- `workout_logs.csv` → Feature engineering Mod STATUS\n",
        "- `sessions.csv` → Analisi macro-ciclo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6M2Sj8AjOcV"
      },
      "source": [
        "**CELL 10 — (Python) Derive workoutlogs (exercise-level) + sessions (session-level)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHKvVs7JjRHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f052e40-21c8-4b4b-e5c1-921436946d6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   workoutid  userid        date sessiontag  exerciseid  setsdone  \\\n",
              " 0          1       1  2024-09-06       Push           1         5   \n",
              " 1          1       1  2024-09-06       Push           4         2   \n",
              " 2          1       1  2024-09-06       Push           8         1   \n",
              " 3          1       1  2024-09-06       Push          10         3   \n",
              " 4          2       1  2024-09-10       Pull           2         4   \n",
              " \n",
              "    repsdonetotal  repsdoneavg  loaddonekg  rpedone  loadintendedkg  \\\n",
              " 0             53        10.60       31.25     7.10           33.25   \n",
              " 1             21        10.50       21.12     7.75           21.00   \n",
              " 2             12        12.00       29.00     7.00           28.50   \n",
              " 3             25         8.33       23.00     7.17           22.50   \n",
              " 4             37         9.25       35.00     7.50           37.25   \n",
              " \n",
              "    reps_target_avg  setsplanned  repsmin  repsmax  rirtarget  \\\n",
              " 0        11.200000            5       10       14          2   \n",
              " 1        10.000000            2        9       15          2   \n",
              " 2        12.000000            3       12       18          2   \n",
              " 3         8.333333            3        6       10          4   \n",
              " 4         9.250000            5        7       11          2   \n",
              " \n",
              "    gapadherencescore  \n",
              " 0              0.960  \n",
              " 1              1.015  \n",
              " 2              0.808  \n",
              " 3              1.010  \n",
              " 4              0.913  ,\n",
              "    workoutid  userid        date sessiontag  total_sets  total_reps  \\\n",
              " 0          1       1  2024-09-06       Push          11         111   \n",
              " 1          2       1  2024-09-10       Pull           9         100   \n",
              " 2          3       1  2024-09-13       Legs          13         101   \n",
              " 3          4       1  2024-09-14       Push          10          93   \n",
              " 4          5       1  2024-09-16       Pull          10          95   \n",
              " \n",
              "    volume_kg  sRPE  \n",
              " 0    3083.50  7.23  \n",
              " 1    3129.75  7.22  \n",
              " 2    3587.00  7.54  \n",
              " 3    2538.50  7.15  \n",
              " 4    3276.00  7.40  )"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# join plan -> per calcolare gapadherencescore a livello esercizio\n",
        "plan_key = [\"workoutid\",\"userid\",\"date\",\"sessiontag\",\"exerciseid\"]\n",
        "df_plan_keyed = df_plan[plan_key + [\"setsplanned\",\"repsmin\",\"repsmax\",\"rirtarget\"]].copy()\n",
        "\n",
        "# aggregate sets -> exercise\n",
        "gex = df_sets.groupby([\"workoutid\",\"userid\",\"date\",\"sessiontag\",\"exerciseid\"], as_index=False).agg(\n",
        "    setsdone=(\"set_index\",\"max\"),\n",
        "    repsdonetotal=(\"reps_done\",\"sum\"),\n",
        "    repsdoneavg=(\"reps_done\",\"mean\"),\n",
        "    loaddonekg=(\"load_done_kg\",\"median\"),\n",
        "    rpedone=(\"rpe_done\",\"mean\"),\n",
        "    loadintendedkg=(\"load_intended_kg\",\"median\"),\n",
        "    reps_target_avg=(\"reps_target\",\"mean\"),\n",
        ")\n",
        "\n",
        "df_logs = gex.merge(df_plan_keyed, on=plan_key, how=\"left\")\n",
        "\n",
        "# gapadherencescore\n",
        "carratio = (df_logs[\"loaddonekg\"] / df_logs[\"loadintendedkg\"]).replace([np.inf, -np.inf], np.nan).fillna(1.0)\n",
        "sratio = (df_logs[\"setsdone\"] / df_logs[\"setsplanned\"]).replace([np.inf, -np.inf], np.nan).fillna(1.0)\n",
        "# reps target “centrale” ~ media target\n",
        "repratio = (df_logs[\"repsdoneavg\"] / df_logs[\"reps_target_avg\"]).replace([np.inf, -np.inf], np.nan).fillna(1.0)\n",
        "\n",
        "gap = 0.45*carratio + 0.30*sratio + 0.25*repratio\n",
        "df_logs[\"gapadherencescore\"] = np.clip(gap, 0.3, 1.8).round(3)\n",
        "\n",
        "df_logs[\"repsdoneavg\"] = df_logs[\"repsdoneavg\"].round(2)\n",
        "df_logs[\"loaddonekg\"] = df_logs[\"loaddonekg\"].round(2)\n",
        "df_logs[\"rpedone\"] = df_logs[\"rpedone\"].round(2)\n",
        "\n",
        "# sessions (session-level)\n",
        "df_sessions = df_sets.groupby([\"workoutid\",\"userid\",\"date\",\"sessiontag\"], as_index=False).agg(\n",
        "    total_sets=(\"set_index\",\"count\"),\n",
        "    total_reps=(\"reps_done\",\"sum\"),\n",
        "    volume_kg=(\"load_done_kg\", lambda x: float(np.nansum(x.values))),  # solo somma load (non volume)\n",
        ")\n",
        "# volume vero = sum(load*reps)\n",
        "tmp = df_sets.copy()\n",
        "tmp[\"load_done_kg_0\"] = tmp[\"load_done_kg\"].fillna(0.0)\n",
        "tmp[\"volume_kg\"] = tmp[\"load_done_kg_0\"] * tmp[\"reps_done\"].astype(float)\n",
        "df_sessions = tmp.groupby([\"workoutid\",\"userid\",\"date\",\"sessiontag\"], as_index=False).agg(\n",
        "    total_sets=(\"set_index\",\"count\"),\n",
        "    total_reps=(\"reps_done\",\"sum\"),\n",
        "    volume_kg=(\"volume_kg\",\"sum\"),\n",
        "    sRPE=(\"rpe_done\",\"mean\")\n",
        ")\n",
        "df_sessions[\"sRPE\"] = df_sessions[\"sRPE\"].round(2)\n",
        "\n",
        "df_logs.head(), df_sessions.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owXaiD0lFCjy"
      },
      "source": [
        "---\n",
        "#11. **Compute Banister Daily Series**\n",
        "\n",
        "Calcolo serie temporale fitness/fatigue.\n",
        "\n",
        "## **Modello Banister (Impulse-Response)**\n",
        "\n",
        "Per ogni utente, su ogni giorno `[start_date, end_date]`:\n",
        "\n",
        "### **Fitness (F) — Adattamento Lungo Termine**\n",
        "```\n",
        "F(t) = Σ_{i=0}^{t} u(i) × exp(-(t-i)/tauF)\n",
        "```\n",
        "- `tauF` ~ 45 giorni (personalizzato)\n",
        "- Accumulo lento, decay lento\n",
        "\n",
        "### **Fatigue (D) — Affaticamento Breve Termine**\n",
        "```\n",
        "D(t) = Σ_{i=0}^{t} u(i) × exp(-(t-i)/tauD)\n",
        "```\n",
        "- `tauD` ~ 7 giorni (personalizzato)\n",
        "- Accumulo rapido, decay rapido\n",
        "\n",
        "### **Performance (P)**\n",
        "```\n",
        "P(t) = betaF × F(t) - betaD × D(t)\n",
        "```\n",
        "- P > 0: forma positiva\n",
        "- P < 0: overreaching\n",
        "- P crescente: supercompensazione\n",
        "\n",
        "## **Output**\n",
        "`df_ban` (banister_daily.csv):\n",
        "- Una riga per (userid, date)\n",
        "- Colonne: impulse, F, D, P, tauF, tauD, betaF, betaD\n",
        "\n",
        "---\n",
        "\n",
        " **Uso**: Input principale Mod IMPETUS (regressione trend).\n",
        "\n",
        " Implementazione $O(L^2)$ per utente. Per $L > 1000$ considerare algoritmi con efficienza maggiore.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJzKTmHhjR47"
      },
      "source": [
        "**CELL 11 — (Python) Compute Banister daily**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouQvRYJEJF0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4283787b-f4de-4850-9fc8-b4dd58cafc64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userid        date    impulse            F            D          P  \\\n",
              "0       1  2024-09-06  2212.7875  2212.787500  2212.787500 -11.063937   \n",
              "1       1  2024-09-07     0.0000  2165.058770  1945.885263  -7.537691   \n",
              "2       1  2024-09-08     0.0000  2118.359524  1711.176268  -4.484049   \n",
              "3       1  2024-09-09     0.0000  2072.667558  1504.777428  -1.844986   \n",
              "4       1  2024-09-10  2257.9625  4285.923646  3581.236525 -10.859311   \n",
              "\n",
              "        tauF      tauD  betaF  betaD  \n",
              "0  45.859934  7.779921   0.01  0.015  \n",
              "1  45.859934  7.779921   0.01  0.015  \n",
              "2  45.859934  7.779921   0.01  0.015  \n",
              "3  45.859934  7.779921   0.01  0.015  \n",
              "4  45.859934  7.779921   0.01  0.015  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a930cfb2-21ab-465c-8bb2-05605b86ea11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>date</th>\n",
              "      <th>impulse</th>\n",
              "      <th>F</th>\n",
              "      <th>D</th>\n",
              "      <th>P</th>\n",
              "      <th>tauF</th>\n",
              "      <th>tauD</th>\n",
              "      <th>betaF</th>\n",
              "      <th>betaD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2024-09-06</td>\n",
              "      <td>2212.7875</td>\n",
              "      <td>2212.787500</td>\n",
              "      <td>2212.787500</td>\n",
              "      <td>-11.063937</td>\n",
              "      <td>45.859934</td>\n",
              "      <td>7.779921</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2024-09-07</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2165.058770</td>\n",
              "      <td>1945.885263</td>\n",
              "      <td>-7.537691</td>\n",
              "      <td>45.859934</td>\n",
              "      <td>7.779921</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2024-09-08</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2118.359524</td>\n",
              "      <td>1711.176268</td>\n",
              "      <td>-4.484049</td>\n",
              "      <td>45.859934</td>\n",
              "      <td>7.779921</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2024-09-09</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2072.667558</td>\n",
              "      <td>1504.777428</td>\n",
              "      <td>-1.844986</td>\n",
              "      <td>45.859934</td>\n",
              "      <td>7.779921</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2024-09-10</td>\n",
              "      <td>2257.9625</td>\n",
              "      <td>4285.923646</td>\n",
              "      <td>3581.236525</td>\n",
              "      <td>-10.859311</td>\n",
              "      <td>45.859934</td>\n",
              "      <td>7.779921</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a930cfb2-21ab-465c-8bb2-05605b86ea11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a930cfb2-21ab-465c-8bb2-05605b86ea11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a930cfb2-21ab-465c-8bb2-05605b86ea11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_ban"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "def compute_banister_daily(cfg: CFG, df_users: pd.DataFrame, df_impulse: pd.DataFrame, df_ban_meta: pd.DataFrame):\n",
        "    # per ogni utente crea serie giornaliera sul range [start_u, end_u]\n",
        "    rows = []\n",
        "    for u in df_users.itertuples(index=False):\n",
        "        uid = int(u.userid)\n",
        "        start_u = date.fromisoformat(u.start_date)\n",
        "        end_u = date.fromisoformat(u.end_date)\n",
        "\n",
        "        meta = df_ban_meta[df_ban_meta[\"userid\"] == uid].iloc[0].to_dict()\n",
        "        tauF = float(meta[\"tauF\"]); tauD = float(meta[\"tauD\"])\n",
        "        betaF = float(meta[\"betaF\"]); betaD = float(meta[\"betaD\"])\n",
        "\n",
        "        days = [start_u + timedelta(days=i) for i in range((end_u - start_u).days + 1)]\n",
        "        days_iso = [d.isoformat() for d in days]\n",
        "\n",
        "        sub = df_impulse[df_impulse[\"userid\"] == uid].copy()\n",
        "        imp_map = dict(zip(sub[\"date\"].astype(str), sub[\"impulse\"].astype(float)))\n",
        "\n",
        "        uts = np.array([float(imp_map.get(d, 0.0)) for d in days_iso], dtype=float)\n",
        "        L = len(uts)\n",
        "        wF = exp_weights(L, tauF)\n",
        "        wD = exp_weights(L, tauD)\n",
        "\n",
        "        # calcolo cumulativo “naive” O(L^2) (ok per dataset medio); ottimizzabile se serve\n",
        "        F = np.array([float(np.sum(uts[:i+1][::-1] * wF[:i+1])) for i in range(L)], dtype=float)\n",
        "        D = np.array([float(np.sum(uts[:i+1][::-1] * wD[:i+1])) for i in range(L)], dtype=float)\n",
        "        P = betaF * F - betaD * D\n",
        "\n",
        "        for i, d in enumerate(days_iso):\n",
        "            rows.append({\n",
        "                \"userid\": uid,\n",
        "                \"date\": d,\n",
        "                \"impulse\": float(uts[i]),\n",
        "                \"F\": float(F[i]),\n",
        "                \"D\": float(D[i]),\n",
        "                \"P\": float(P[i]),\n",
        "                \"tauF\": tauF,\n",
        "                \"tauD\": tauD,\n",
        "                \"betaF\": betaF,\n",
        "                \"betaD\": betaD,\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "df_ban = compute_banister_daily(cfg, df_users, df_impulse, df_ban_meta)\n",
        "df_ban.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97P1-o9zFCj0"
      },
      "source": [
        "---\n",
        "#12. **Validation & Save**\n",
        "\n",
        "Validazioni dataset + salvataggio CSV + ZIP.\n",
        "\n",
        "## **Validazioni Automatiche**\n",
        "\n",
        "1. **Date Range**: set in `[start_date, end_date]` utente\n",
        "2. **Foreign Keys**: exerciseid validi\n",
        "3. **Skip Rate**: Beginner 10-13%, Intermediate 6-9%, Advanced 4-7%\n",
        "4. **Missingness**: RPE ~2%, Load ~1%, Feedback ~2%\n",
        "5. **Quantization**: Load multipli 0.25 kg, RPE multipli 0.5\n",
        "6. **Progressive Overload**: capacità medie crescenti (utenti > 180 giorni)\n",
        "\n",
        "## **File Output**\n",
        "\n",
        "In cartella `cfg.outdir` (default: `data_synth_setlevel/`):\n",
        "\n",
        "| File | Descrizione | Size (300 users) |\n",
        "|------|-------------|------------------|\n",
        "| `users.csv` | Anagrafica + latenti + date window | ~50 KB |\n",
        "| `exercises.csv` | Catalogo esercizi | ~5 KB |\n",
        "| `workouts.csv` | Metadata sessioni | ~500 KB |\n",
        "| `workout_plan.csv` | Prescrizioni | ~2 MB |\n",
        "| **`workout_sets.csv`** | **Set-level (PRINCIPALE)** | **~30 MB** |\n",
        "| `workout_logs.csv` | Exercise-level | ~10 MB |\n",
        "| `sessions.csv` | Session-level | ~3 MB |\n",
        "| `banister_daily.csv` | Serie F/D/P | ~20 MB |\n",
        "| `capabilities.json` | Capacità iniziali | ~500 KB |\n",
        "| `metrics.json` | Summary validazione | ~1 KB |\n",
        "\n",
        "### **ZIP Archive**\n",
        "Tutti i file compressi in `{outdir}.zip` per download.\n",
        "\n",
        "---\n",
        "\n",
        " Se validazioni passano (`True`): dataset pronto ML.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyg4jg9QjWsQ"
      },
      "source": [
        "**CELL 12 — (Python) Validations + Save CSV + Zip**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzvWdodjjZLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad384b31-c82d-4c8a-a3b5-90e75d1a1683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sets_in_range': True,\n",
              " 'set_id_unique': True,\n",
              " 'no_sets_for_skipped': True,\n",
              " 'sets_required_cols_nonnull': True}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "def validate_dataset(df_users, df_workouts, df_plan, df_sets, df_logs, df_sessions, df_ban):\n",
        "    checks = {}\n",
        "\n",
        "    # 1) date range per utente\n",
        "    u = df_users.copy()\n",
        "    u[\"start_date\"] = pd.to_datetime(u[\"start_date\"]).dt.date\n",
        "    u[\"end_date\"] = pd.to_datetime(u[\"end_date\"]).dt.date\n",
        "    s = df_sets.copy()\n",
        "    s[\"date\"] = pd.to_datetime(s[\"date\"]).dt.date\n",
        "\n",
        "    merged = s.merge(u[[\"userid\",\"start_date\",\"end_date\"]], on=\"userid\", how=\"left\")\n",
        "    checks[\"sets_in_range\"] = bool(((merged[\"date\"] >= merged[\"start_date\"]) & (merged[\"date\"] <= merged[\"end_date\"])).all())\n",
        "\n",
        "    # 2) set_id unico\n",
        "    checks[\"set_id_unique\"] = bool(df_sets[\"set_id\"].is_unique)\n",
        "\n",
        "    # 3) consistenza workoutstatus: se session skipped, non dovrebbero esserci set\n",
        "    w = df_workouts.copy()\n",
        "    sw = s.merge(w[[\"workoutid\",\"workoutstatus\"]], on=\"workoutid\", how=\"left\")\n",
        "    checks[\"no_sets_for_skipped\"] = bool((sw[sw[\"workoutstatus\"] == \"skipped\"].shape[0] == 0))\n",
        "\n",
        "    # 4) chiavi minime non nulle\n",
        "    required_cols = [\"userid\",\"date\",\"exerciseid\",\"set_index\"]\n",
        "    checks[\"sets_required_cols_nonnull\"] = bool(df_sets[required_cols].notnull().all().all())\n",
        "\n",
        "    return checks\n",
        "\n",
        "checks = validate_dataset(df_users, df_workouts, df_plan, df_sets, df_logs, df_sessions, df_ban)\n",
        "checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN2DE0sJjfFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c41195-9d36-4cee-9ee3-8a6f9966d9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: data_synth_setlevel/ (stored 0%)\n",
            "  adding: data_synth_setlevel/banisterdaily.csv (deflated 72%)\n",
            "  adding: data_synth_setlevel/workout_sets.csv (deflated 84%)\n",
            "  adding: data_synth_setlevel/validation_checks.json (deflated 32%)\n",
            "  adding: data_synth_setlevel/workoutexercises.csv (deflated 84%)\n",
            "  adding: data_synth_setlevel/workouts.csv (deflated 70%)\n",
            "  adding: data_synth_setlevel/workoutlogs.csv (deflated 78%)\n",
            "  adding: data_synth_setlevel/users.csv (deflated 68%)\n",
            "  adding: data_synth_setlevel/sessions.csv (deflated 72%)\n",
            "  adding: data_synth_setlevel/exercises.csv (deflated 59%)\n",
            "DONE: data_synth_setlevel.zip\n"
          ]
        }
      ],
      "source": [
        "# Save\n",
        "df_users.to_csv(OUTDIR / \"users.csv\", index=False)\n",
        "df_ex.to_csv(OUTDIR / \"exercises.csv\", index=False)\n",
        "df_workouts.to_csv(OUTDIR / \"workouts.csv\", index=False)\n",
        "df_plan.to_csv(OUTDIR / \"workoutexercises.csv\", index=False)     # plan per esercizio (come prima) [file:1]\n",
        "df_sets.to_csv(OUTDIR / \"workout_sets.csv\", index=False)          # canonico set-level\n",
        "df_logs.to_csv(OUTDIR / \"workoutlogs.csv\", index=False)           # derivato exercise-level (compat) [file:1]\n",
        "df_sessions.to_csv(OUTDIR / \"sessions.csv\", index=False)          # derivato session-level\n",
        "df_ban.to_csv(OUTDIR / \"banisterdaily.csv\", index=False)          # compat concettuale [file:1]\n",
        "\n",
        "with open(OUTDIR / \"validation_checks.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(checks, f, indent=2)\n",
        "\n",
        "# Zip per download\n",
        "zip_name = f\"{cfg.outdir}.zip\"\n",
        "!zip -r {zip_name} {cfg.outdir}\n",
        "print(\"DONE:\", zip_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMMRNSBSIvnu"
      },
      "source": [
        "---\n",
        "# **Validazioni Post-Generazione**\n",
        "\n",
        "Controlli qualità dataset.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAbDJrmfIvnu"
      },
      "source": [
        "## **Skip Rate per Livello**\n",
        "\n",
        "Target: Beginner 10-13%, Intermediate 6-9%, Advanced 4-7%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJCfYMCaJZgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2994dd-8750-41c2-d70d-1e237ddfb8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skip-rate per livello:\n",
            "experience_label\n",
            "Advanced        0.071001\n",
            "Beginner        0.131598\n",
            "Intermediate    0.087638\n",
            "Name: is_skipped, dtype: float64\n",
            "\n",
            "Mean z_skip per livello:\n",
            "experience_label\n",
            "Advanced       -2.646355\n",
            "Beginner       -1.900262\n",
            "Intermediate   -2.369068\n",
            "Name: z_skip, dtype: float64\n",
            "\n",
            "Mean p_skip per livello:\n",
            "experience_label\n",
            "Advanced        0.066495\n",
            "Beginner        0.130511\n",
            "Intermediate    0.085901\n",
            "Name: p_skip, dtype: float64\n",
            "\n",
            "Distribuzione p_skip:\n",
            "count    169292.0000\n",
            "mean          0.0993\n",
            "std           0.0250\n",
            "min           0.0390\n",
            "25%           0.0810\n",
            "50%           0.0903\n",
            "75%           0.1233\n",
            "max           0.1824\n",
            "Name: p_skip, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# === SKIP-RATE ===\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = OUTDIR if \"OUTDIR\" in globals() else Path(\"data_synth_setlevel\")\n",
        "workouts = pd.read_csv(DATA_DIR / \"workouts.csv\")\n",
        "\n",
        "# experience_label è già in workouts.csv, non serve merge!\n",
        "workouts[\"is_skipped\"] = (workouts[\"workoutstatus\"] == \"skipped\").astype(int)\n",
        "\n",
        "print(\"Skip-rate per livello:\")\n",
        "print(workouts.groupby(\"experience_label\")[\"is_skipped\"].mean().sort_index())\n",
        "\n",
        "# Debug z/p/fatigue_term\n",
        "if \"z_skip\" in workouts.columns:\n",
        "    print(\"\\nMean z_skip per livello:\")\n",
        "    print(workouts.groupby(\"experience_label\")[\"z_skip\"].mean().sort_index())\n",
        "\n",
        "    print(\"\\nMean p_skip per livello:\")\n",
        "    print(workouts.groupby(\"experience_label\")[\"p_skip\"].mean().sort_index())\n",
        "\n",
        "    print(\"\\nDistribuzione p_skip:\")\n",
        "    print(workouts[\"p_skip\"].describe().round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKoLoPngIvnu"
      },
      "source": [
        "## **Dataset Summary**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxkRk1DKIvnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67fbe7b-0e3f-431d-8829-24c6b4e41355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "  DATASET SUMMARY\n",
            "============================================================\n",
            "\n",
            "Utenti: 1000\n",
            "Sessioni: 169292\n",
            "Set logs: 1401317\n",
            "\n",
            "Distribuzione Livelli:\n",
            "experience_label\n",
            "Intermediate    55.1\n",
            "Beginner        34.5\n",
            "Advanced        10.4\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "============================================================\n",
            " Dataset pronto!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"  DATASET SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nUtenti: {len(df_users)}\")\n",
        "print(f\"Sessioni: {len(df_workouts)}\")\n",
        "print(f\"Set logs: {len(df_sets)}\")\n",
        "print(f\"\\nDistribuzione Livelli:\")\n",
        "print((df_users['experience_label'].value_counts(normalize=True) * 100).round(1))\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" Dataset pronto!\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMKGbds3IWYmW/5hLNmbyTz"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}